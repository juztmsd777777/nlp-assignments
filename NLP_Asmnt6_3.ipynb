{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/juztmsd777777/nlp-assignments/blob/main/NLP_Asmnt6_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LDA with sample data\n"
      ],
      "metadata": {
        "id": "4rRHP_23L770"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_excel(\"/content/LDA-Data.xlsx\")\n",
        "df.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "p5U4R_m7IyMo",
        "outputId": "ca083d31-9de1-40e0-8245-55341e6ac4bf"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                             News\n",
              "0   Virat scored century in match\n",
              "1            BJP won in elections\n",
              "2  Bumra took 5 wicket in a match\n",
              "3  Congress form state government"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-583128c7-925e-4170-aac4-cf7bb5b316c4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>News</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Virat scored century in match</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>BJP won in elections</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Bumra took 5 wicket in a match</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Congress form state government</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-583128c7-925e-4170-aac4-cf7bb5b316c4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-583128c7-925e-4170-aac4-cf7bb5b316c4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-583128c7-925e-4170-aac4-cf7bb5b316c4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 4,\n  \"fields\": [\n    {\n      \"column\": \"News\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"BJP won in elections\",\n          \"Congress form state government\",\n          \"Virat scored century in match\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "# Download necessary NLTK data (including punkt_tab)\n",
        "nltk.download('stopwords', quiet=True)\n",
        "nltk.download('wordnet', quiet=True)\n",
        "nltk.download('punkt_tab', quiet=True)  # Changed from 'punkt' to 'punkt_tab'\n",
        "nltk.download('omw-1.4', quiet=True)\n",
        "\n",
        "# Initialize lemmatizer and stopwords\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def preprocess_text(text):\n",
        "    # Handle non-string inputs\n",
        "    if not isinstance(text, str):\n",
        "        return ''\n",
        "\n",
        "    # 1. Clean Text: convert to lowercase, remove non-alphabetic characters\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^a-z]', ' ', text)\n",
        "\n",
        "    # 2. Word Tokenization\n",
        "    words = nltk.word_tokenize(text)\n",
        "\n",
        "    # 3. Stopword removal & 4. Lemmatization\n",
        "    processed_words = []\n",
        "    for word in words:\n",
        "        if word not in stop_words and len(word) > 1:  # Remove single character words\n",
        "            processed_words.append(lemmatizer.lemmatize(word))\n",
        "\n",
        "    # 5. Rejoin\n",
        "    return ' '.join(processed_words)\n",
        "\n",
        "# Handle missing values (if any)\n",
        "df['News'] = df['News'].fillna('')\n",
        "\n",
        "# Apply the preprocessing function to the 'News' column\n",
        "df['Processed_News'] = df['News'].apply(preprocess_text)\n",
        "\n",
        "print(\"Original News and Processed News:\")\n",
        "print(df[['News', 'Processed_News']].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zbn6u3tQKIJN",
        "outputId": "63377a7d-2faf-4d20-ff3e-e6bdb815dbf0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original News and Processed News:\n",
            "                             News                  Processed_News\n",
            "0   Virat scored century in match      virat scored century match\n",
            "1            BJP won in elections                    bjp election\n",
            "2  Bumra took 5 wicket in a match         bumra took wicket match\n",
            "3  Congress form state government  congress form state government\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Initialize CountVectorizer\n",
        "vectorizer = CountVectorizer()\n",
        "\n",
        "# Fit and transform the 'Processed_News' column to create the BoW matrix\n",
        "bow_matrix = vectorizer.fit_transform(df['Processed_News'])\n",
        "\n",
        "# Get the feature names (vocabulary)\n",
        "feature_names = vectorizer.get_feature_names_out()\n",
        "\n",
        "print(\"Vocabulary (Feature Names):\")\n",
        "print(feature_names)\n",
        "print(\"\\nShape of BoW matrix:\", bow_matrix.shape)\n",
        "\n",
        "# To display a part of the BoW matrix, convert it to a DataFrame (optional, for better viewing)\n",
        "bow_df = pd.DataFrame(bow_matrix.toarray(), columns=feature_names)\n",
        "print(\"\\nFirst 5 rows of the BoW matrix:\")\n",
        "print(bow_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JtU_4oXIKPDi",
        "outputId": "9397c84e-e1f6-4377-b2c2-8b848a402e6a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary (Feature Names):\n",
            "['bjp' 'bumra' 'century' 'congress' 'election' 'form' 'government' 'match'\n",
            " 'scored' 'state' 'took' 'virat' 'wicket']\n",
            "\n",
            "Shape of BoW matrix: (4, 13)\n",
            "\n",
            "First 5 rows of the BoW matrix:\n",
            "   bjp  bumra  century  congress  election  form  government  match  scored  \\\n",
            "0    0      0        1         0         0     0           0      1       1   \n",
            "1    1      0        0         0         1     0           0      0       0   \n",
            "2    0      1        0         0         0     0           0      1       0   \n",
            "3    0      0        0         1         0     1           1      0       0   \n",
            "\n",
            "   state  took  virat  wicket  \n",
            "0      0     0      1       0  \n",
            "1      0     0      0       0  \n",
            "2      0     1      0       1  \n",
            "3      1     0      0       0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "\n",
        "# Define the number of topics (you can change this based on your needs)\n",
        "num_topics = 2\n",
        "\n",
        "# Initialize LDA model\n",
        "lda_model = LatentDirichletAllocation(n_components=num_topics, random_state=42)\n",
        "\n",
        "# Fit the model to the BoW matrix\n",
        "lda_output = lda_model.fit_transform(bow_matrix)\n",
        "\n",
        "# Display the topics and their top words\n",
        "def display_topics(model, feature_names, no_top_words):\n",
        "    for topic_idx, topic in enumerate(model.components_): # Corrected from components__ to components_\n",
        "        print(f\"Topic {topic_idx}:\")\n",
        "        print(\" \".join([feature_names[i] for i in topic.argsort()[:-no_top_words - 1:-1]]))\n",
        "\n",
        "no_top_words = 5\n",
        "print(\"\\nLDA Topics:\")\n",
        "display_topics(lda_model, feature_names, no_top_words)\n",
        "\n",
        "# Add the dominant topic to the original DataFrame\n",
        "df['Dominant_Topic'] = lda_output.argmax(axis=1)\n",
        "\n",
        "print(\"\\nDataFrame with Dominant Topic:\")\n",
        "print(df[['News', 'Dominant_Topic']].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p1Ag-VFTKtdl",
        "outputId": "249840e1-3a90-4d3f-beec-d1c7ee4a569f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "LDA Topics:\n",
            "Topic 0:\n",
            "form government congress state election\n",
            "Topic 1:\n",
            "match virat century scored took\n",
            "\n",
            "DataFrame with Dominant Topic:\n",
            "                             News  Dominant_Topic\n",
            "0   Virat scored century in match               1\n",
            "1            BJP won in elections               0\n",
            "2  Bumra took 5 wicket in a match               1\n",
            "3  Congress form state government               0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LDA with kaggle data"
      ],
      "metadata": {
        "id": "J1f1JG4qMCXc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "\n",
        "nltk.download('stopwords', quiet=True)\n",
        "nltk.download('wordnet', quiet=True)\n",
        "nltk.download('punkt_tab', quiet=True)\n",
        "nltk.download('omw-1.4', quiet=True)\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def preprocess_text(text):\n",
        "    if not isinstance(text, str):\n",
        "        return ''\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^a-z]', ' ', text)\n",
        "    words = nltk.word_tokenize(text)\n",
        "    processed_words = []\n",
        "    for word in words:\n",
        "        if word not in stop_words and len(word) > 1:\n",
        "            processed_words.append(lemmatizer.lemmatize(word))\n",
        "    return ' '.join(processed_words)\n",
        "\n",
        "# LOAD\n",
        "df = pd.read_csv(\"/content/arxiv_data.csv\", on_bad_lines='skip', engine='python', nrows=1000)\n",
        "\n",
        "# PREPROCESS\n",
        "df['titles'] = df['titles'].fillna('')\n",
        "df['summaries'] = df['summaries'].fillna('')\n",
        "df['text_content'] = df['titles'] + ' ' + df['summaries']\n",
        "df['Processed_Text'] = df['text_content'].apply(preprocess_text)\n",
        "\n",
        "# BOW\n",
        "vectorizer = CountVectorizer()\n",
        "bow_matrix = vectorizer.fit_transform(df['Processed_Text'])\n",
        "feature_names = vectorizer.get_feature_names_out()\n",
        "\n",
        "# OUTPUT\n",
        "num_topics = 2\n",
        "lda_model = LatentDirichletAllocation(n_components=num_topics, random_state=42)\n",
        "lda_output = lda_model.fit_transform(bow_matrix)\n",
        "\n",
        "def display_topics(model, feature_names, no_top_words):\n",
        "    for topic_idx, topic in enumerate(model.components_):\n",
        "        print(f\"Topic {topic_idx}:\")\n",
        "        print(\" \".join([feature_names[i] for i in topic.argsort()[:-no_top_words - 1:-1]]))\n",
        "\n",
        "print(\"LDA Topics:\")\n",
        "display_topics(lda_model, feature_names, 5)\n",
        "df['Dominant_Topic'] = lda_output.argmax(axis=1)\n",
        "print(\"\\nDocument and Topic:\")\n",
        "print(df[['text_content', 'Dominant_Topic']])"
      ],
      "metadata": {
        "id": "LvCUEtZ_XE4E",
        "outputId": "423e49d2-da02-4d86-824b-07c6d71fa354",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LDA Topics:\n",
            "Topic 0:\n",
            "segmentation image network method model\n",
            "Topic 1:\n",
            "image segmentation domain method learning\n",
            "\n",
            "Document and Topic:\n",
            "                                          text_content  Dominant_Topic\n",
            "0    Survey on Semantic Stereo Matching / Semantic ...               0\n",
            "1    FUTURE-AI: Guiding Principles and Consensus Re...               1\n",
            "2    Enforcing Mutual Consistency of Hard Regions f...               0\n",
            "3    Parameter Decoupling Strategy for Semi-supervi...               0\n",
            "4    Background-Foreground Segmentation for Interio...               0\n",
            "..                                                 ...             ...\n",
            "995  DeepIGeoS: A Deep Interactive Geodesic Framewo...               0\n",
            "996  3D Densely Convolutional Networks for Volumetr...               0\n",
            "997  UI-Net: Interactive Artificial Neural Networks...               0\n",
            "998  One-Shot Learning for Semantic Segmentation Lo...               0\n",
            "999  Exploring and Exploiting Diversity for Image S...               0\n",
            "\n",
            "[1000 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NMF with kaggle data"
      ],
      "metadata": {
        "id": "aeXJgUQCUQIt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.decomposition import NMF\n",
        "\n",
        "nltk.download('stopwords', quiet=True)\n",
        "nltk.download('wordnet', quiet=True)\n",
        "nltk.download('punkt_tab', quiet=True)\n",
        "nltk.download('omw-1.4', quiet=True)\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def preprocess_text(text):\n",
        "    if not isinstance(text, str):\n",
        "        return ''\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^a-z]', ' ', text)\n",
        "    words = nltk.word_tokenize(text)\n",
        "    processed_words = []\n",
        "    for word in words:\n",
        "        if word not in stop_words and len(word) > 1:\n",
        "            processed_words.append(lemmatizer.lemmatize(word))\n",
        "    return ' '.join(processed_words)\n",
        "\n",
        "# LOAD\n",
        "df = pd.read_csv(\"/content/arxiv_data.csv\", on_bad_lines='skip', engine='python', nrows=1000)\n",
        "\n",
        "# PREPROCESS\n",
        "df['titles'] = df['titles'].fillna('')\n",
        "df['summaries'] = df['summaries'].fillna('')\n",
        "df['text_content'] = df['titles'] + ' ' + df['summaries']\n",
        "df['Processed_Text'] = df['text_content'].apply(preprocess_text)\n",
        "\n",
        "# BOW\n",
        "vectorizer = CountVectorizer()\n",
        "bow_matrix = vectorizer.fit_transform(df['Processed_Text'])\n",
        "feature_names = vectorizer.get_feature_names_out()\n",
        "\n",
        "# OUTPUT\n",
        "num_topics = 2\n",
        "nmf_model = NMF(n_components=num_topics, random_state=42)\n",
        "nmf_output = nmf_model.fit_transform(bow_matrix)\n",
        "\n",
        "def display_topics(model, feature_names, no_top_words):\n",
        "    for topic_idx, topic in enumerate(model.components_):\n",
        "        print(f\"Topic {topic_idx}:\")\n",
        "        print(\" \".join([feature_names[i] for i in topic.argsort()[:-no_top_words - 1:-1]]))\n",
        "\n",
        "print(\"NMF Topics:\")\n",
        "display_topics(nmf_model, feature_names, 5)\n",
        "df['Dominant_Topic'] = nmf_output.argmax(axis=1)\n",
        "print(\"\\nDocument and Topic:\")\n",
        "print(df[['text_content', 'Dominant_Topic']])"
      ],
      "metadata": {
        "id": "3V0H4lgEXXVz",
        "outputId": "e235ec14-6137-46fc-d87a-533b51983e4b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NMF Topics:\n",
            "Topic 0:\n",
            "segmentation network learning model method\n",
            "Topic 1:\n",
            "image segmentation method based using\n",
            "\n",
            "Document and Topic:\n",
            "                                          text_content  Dominant_Topic\n",
            "0    Survey on Semantic Stereo Matching / Semantic ...               0\n",
            "1    FUTURE-AI: Guiding Principles and Consensus Re...               1\n",
            "2    Enforcing Mutual Consistency of Hard Regions f...               0\n",
            "3    Parameter Decoupling Strategy for Semi-supervi...               0\n",
            "4    Background-Foreground Segmentation for Interio...               0\n",
            "..                                                 ...             ...\n",
            "995  DeepIGeoS: A Deep Interactive Geodesic Framewo...               0\n",
            "996  3D Densely Convolutional Networks for Volumetr...               0\n",
            "997  UI-Net: Interactive Artificial Neural Networks...               0\n",
            "998  One-Shot Learning for Semantic Segmentation Lo...               1\n",
            "999  Exploring and Exploiting Diversity for Image S...               0\n",
            "\n",
            "[1000 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NMF with sample data\n"
      ],
      "metadata": {
        "id": "YJM2bmWnSSaE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_excel(\"/content/LDA-Data.xlsx\")\n",
        "df.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "outputId": "9127d97b-90be-4873-82ad-b8ef671a6559",
        "id": "ZC0Qk5o1Sa6r"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                             News\n",
              "0   Virat scored century in match\n",
              "1            BJP won in elections\n",
              "2  Bumra took 5 wicket in a match\n",
              "3  Congress form state government"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3d587090-9cda-461c-87a8-66254e8a428c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>News</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Virat scored century in match</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>BJP won in elections</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Bumra took 5 wicket in a match</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Congress form state government</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3d587090-9cda-461c-87a8-66254e8a428c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3d587090-9cda-461c-87a8-66254e8a428c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3d587090-9cda-461c-87a8-66254e8a428c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 4,\n  \"fields\": [\n    {\n      \"column\": \"News\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"BJP won in elections\",\n          \"Congress form state government\",\n          \"Virat scored century in match\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "# Download necessary NLTK data (including punkt_tab)\n",
        "nltk.download('stopwords', quiet=True)\n",
        "nltk.download('wordnet', quiet=True)\n",
        "nltk.download('punkt_tab', quiet=True)  # Changed from 'punkt' to 'punkt_tab'\n",
        "nltk.download('omw-1.4', quiet=True)\n",
        "\n",
        "# Initialize lemmatizer and stopwords\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def preprocess_text(text):\n",
        "    # Handle non-string inputs\n",
        "    if not isinstance(text, str):\n",
        "        return ''\n",
        "\n",
        "    # 1. Clean Text: convert to lowercase, remove non-alphabetic characters\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^a-z]', ' ', text)\n",
        "\n",
        "    # 2. Word Tokenization\n",
        "    words = nltk.word_tokenize(text)\n",
        "\n",
        "    # 3. Stopword removal & 4. Lemmatization\n",
        "    processed_words = []\n",
        "    for word in words:\n",
        "        if word not in stop_words and len(word) > 1:  # Remove single character words\n",
        "            processed_words.append(lemmatizer.lemmatize(word))\n",
        "\n",
        "    # 5. Rejoin\n",
        "    return ' '.join(processed_words)\n",
        "\n",
        "# Handle missing values (if any)\n",
        "df['News'] = df['News'].fillna('')\n",
        "\n",
        "# Apply the preprocessing function to the 'News' column\n",
        "df['Processed_News'] = df['News'].apply(preprocess_text)\n",
        "\n",
        "print(\"Original News and Processed News:\")\n",
        "print(df[['News', 'Processed_News']].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71585baa-9931-4696-ae34-c1f7a389505d",
        "id": "uYvUg1gjSj5d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original News and Processed News:\n",
            "                             News                  Processed_News\n",
            "0   Virat scored century in match      virat scored century match\n",
            "1            BJP won in elections                    bjp election\n",
            "2  Bumra took 5 wicket in a match         bumra took wicket match\n",
            "3  Congress form state government  congress form state government\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Initialize CountVectorizer\n",
        "vectorizer = CountVectorizer()\n",
        "\n",
        "# Fit and transform the 'Processed_News' column to create the BoW matrix\n",
        "bow_matrix = vectorizer.fit_transform(df['Processed_News'])\n",
        "\n",
        "# Get the feature names (vocabulary)\n",
        "feature_names = vectorizer.get_feature_names_out()\n",
        "\n",
        "print(\"Vocabulary (Feature Names):\")\n",
        "print(feature_names)\n",
        "print(\"\\nShape of BoW matrix:\", bow_matrix.shape)\n",
        "\n",
        "# To display a part of the BoW matrix, convert it to a DataFrame (optional, for better viewing)\n",
        "bow_df = pd.DataFrame(bow_matrix.toarray(), columns=feature_names)\n",
        "print(\"\\nFirst 5 rows of the BoW matrix:\")\n",
        "print(bow_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e347ab9-8392-4e8f-b3c6-4b250cd08a2d",
        "id": "-ZhP5C9tS-HE"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary (Feature Names):\n",
            "['bjp' 'bumra' 'century' 'congress' 'election' 'form' 'government' 'match'\n",
            " 'scored' 'state' 'took' 'virat' 'wicket']\n",
            "\n",
            "Shape of BoW matrix: (4, 13)\n",
            "\n",
            "First 5 rows of the BoW matrix:\n",
            "   bjp  bumra  century  congress  election  form  government  match  scored  \\\n",
            "0    0      0        1         0         0     0           0      1       1   \n",
            "1    1      0        0         0         1     0           0      0       0   \n",
            "2    0      1        0         0         0     0           0      1       0   \n",
            "3    0      0        0         1         0     1           1      0       0   \n",
            "\n",
            "   state  took  virat  wicket  \n",
            "0      0     0      1       0  \n",
            "1      0     0      0       0  \n",
            "2      0     1      0       1  \n",
            "3      1     0      0       0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import NMF\n",
        "\n",
        "# Define the number of topics (you can change this based on your needs)\n",
        "num_topics = 2\n",
        "\n",
        "# Initialize NMF model\n",
        "nmf_model = NMF(n_components=num_topics, random_state=42, init='nndsvda', tol=5e-3)\n",
        "\n",
        "# Fit the model to the BoW matrix\n",
        "nmf_output = nmf_model.fit_transform(bow_matrix)\n",
        "\n",
        "# Display the topics and their top words\n",
        "def display_topics(model, feature_names, no_top_words):\n",
        "    for topic_idx, topic in enumerate(model.components_):\n",
        "        print(f\"Topic {topic_idx}:\")\n",
        "        print(\" \".join([feature_names[i] for i in topic.argsort()[:-no_top_words - 1:-1]]))\n",
        "\n",
        "no_top_words = 5\n",
        "print(\"\\nNMF Topics:\")\n",
        "display_topics(nmf_model, feature_names, no_top_words)\n",
        "\n",
        "# Add the dominant topic to the original DataFrame\n",
        "df['Dominant_Topic'] = nmf_output.argmax(axis=1)\n",
        "\n",
        "print(\"\\nDataFrame with Dominant Topic:\")\n",
        "print(df[['News', 'Dominant_Topic']].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dff0ad75-c1f2-415e-b632-27aacecb53c5",
        "id": "LLiKBpVfTDfQ"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "NMF Topics:\n",
            "Topic 0:\n",
            "match scored virat century wicket\n",
            "Topic 1:\n",
            "state form congress government election\n",
            "\n",
            "DataFrame with Dominant Topic:\n",
            "                             News  Dominant_Topic\n",
            "0   Virat scored century in match               0\n",
            "1            BJP won in elections               1\n",
            "2  Bumra took 5 wicket in a match               0\n",
            "3  Congress form state government               1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NMF with sample data tf idf\n"
      ],
      "metadata": {
        "id": "6DikPLK4YTE7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import NMF\n",
        "\n",
        "nltk.download('stopwords', quiet=True)\n",
        "nltk.download('wordnet', quiet=True)\n",
        "nltk.download('punkt_tab', quiet=True)\n",
        "nltk.download('omw-1.4', quiet=True)\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def preprocess_text(text):\n",
        "    if not isinstance(text, str):\n",
        "        return ''\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^a-z]', ' ', text)\n",
        "    words = nltk.word_tokenize(text)\n",
        "    processed_words = []\n",
        "    for word in words:\n",
        "        if word not in stop_words and len(word) > 1:\n",
        "            processed_words.append(lemmatizer.lemmatize(word))\n",
        "    return ' '.join(processed_words)\n",
        "\n",
        "# LOAD\n",
        "data = {'News': ['Virat scored century in match', 'BJP won in elections', 'Bumra took 5 wicket in a match', 'Congress form state government']}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# PREPROCESS\n",
        "df['News'] = df['News'].fillna('')\n",
        "df['Processed_News'] = df['News'].apply(preprocess_text)\n",
        "\n",
        "# TFIDF\n",
        "vectorizer = TfidfVectorizer()\n",
        "tfidf_matrix = vectorizer.fit_transform(df['Processed_News'])\n",
        "feature_names = vectorizer.get_feature_names_out()\n",
        "\n",
        "# OUTPUT\n",
        "num_topics = 2\n",
        "nmf_model = NMF(n_components=num_topics, random_state=42)\n",
        "nmf_output = nmf_model.fit_transform(tfidf_matrix)\n",
        "\n",
        "def display_topics(model, feature_names, no_top_words):\n",
        "    for topic_idx, topic in enumerate(model.components_):\n",
        "        print(f\"Topic {topic_idx}:\")\n",
        "        print(\" \".join([feature_names[i] for i in topic.argsort()[:-no_top_words - 1:-1]]))\n",
        "\n",
        "print(\"NMF Topics:\")\n",
        "display_topics(nmf_model, feature_names, 5)\n",
        "df['Dominant_Topic'] = nmf_output.argmax(axis=1)\n",
        "print(\"\\nDocument and Topic:\")\n",
        "print(df[['News', 'Dominant_Topic']])"
      ],
      "metadata": {
        "id": "N4kSnoJXYRVj",
        "outputId": "677fda6e-f47a-43d4-c3ae-6e228d209c75",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NMF Topics:\n",
            "Topic 0:\n",
            "match bumra wicket took virat\n",
            "Topic 1:\n",
            "election bjp form government state\n",
            "\n",
            "Document and Topic:\n",
            "                             News  Dominant_Topic\n",
            "0   Virat scored century in match               0\n",
            "1            BJP won in elections               1\n",
            "2  Bumra took 5 wicket in a match               0\n",
            "3  Congress form state government               1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NMF with kaggle data TF IDF"
      ],
      "metadata": {
        "id": "NMGaMCNaX9Sk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import NMF\n",
        "\n",
        "nltk.download('stopwords', quiet=True)\n",
        "nltk.download('wordnet', quiet=True)\n",
        "nltk.download('punkt_tab', quiet=True)\n",
        "nltk.download('omw-1.4', quiet=True)\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def preprocess_text(text):\n",
        "    if not isinstance(text, str):\n",
        "        return ''\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^a-z]', ' ', text)\n",
        "    words = nltk.word_tokenize(text)\n",
        "    processed_words = []\n",
        "    for word in words:\n",
        "        if word not in stop_words and len(word) > 1:\n",
        "            processed_words.append(lemmatizer.lemmatize(word))\n",
        "    return ' '.join(processed_words)\n",
        "\n",
        "# LOAD\n",
        "df = pd.read_csv(\"/content/arxiv_data.csv\", on_bad_lines='skip', engine='python', nrows=1000)\n",
        "\n",
        "# PREPROCESS\n",
        "df['titles'] = df['titles'].fillna('')\n",
        "df['summaries'] = df['summaries'].fillna('')\n",
        "df['text_content'] = df['titles'] + ' ' + df['summaries']\n",
        "df['Processed_Text'] = df['text_content'].apply(preprocess_text)\n",
        "\n",
        "# TFIDF\n",
        "vectorizer = TfidfVectorizer()\n",
        "tfidf_matrix = vectorizer.fit_transform(df['Processed_Text'])\n",
        "feature_names = vectorizer.get_feature_names_out()\n",
        "\n",
        "# OUTPUT\n",
        "num_topics = 2\n",
        "nmf_model = NMF(n_components=num_topics, random_state=42)\n",
        "nmf_output = nmf_model.fit_transform(tfidf_matrix)\n",
        "\n",
        "def display_topics(model, feature_names, no_top_words):\n",
        "    for topic_idx, topic in enumerate(model.components_):\n",
        "        print(f\"Topic {topic_idx}:\")\n",
        "        print(\" \".join([feature_names[i] for i in topic.argsort()[:-no_top_words - 1:-1]]))\n",
        "\n",
        "print(\"NMF Topics:\")\n",
        "display_topics(nmf_model, feature_names, 5)\n",
        "df['Dominant_Topic'] = nmf_output.argmax(axis=1)\n",
        "print(\"\\nDocument and Topic:\")\n",
        "print(df[['text_content', 'Dominant_Topic']])"
      ],
      "metadata": {
        "id": "iYfPt6e-XgbL",
        "outputId": "83992cc6-9cd0-4881-9009-f5c476212a40",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NMF Topics:\n",
            "Topic 0:\n",
            "segmentation image network method model\n",
            "Topic 1:\n",
            "domain supervised data learning annotation\n",
            "\n",
            "Document and Topic:\n",
            "                                          text_content  Dominant_Topic\n",
            "0    Survey on Semantic Stereo Matching / Semantic ...               0\n",
            "1    FUTURE-AI: Guiding Principles and Consensus Re...               0\n",
            "2    Enforcing Mutual Consistency of Hard Regions f...               1\n",
            "3    Parameter Decoupling Strategy for Semi-supervi...               1\n",
            "4    Background-Foreground Segmentation for Interio...               0\n",
            "..                                                 ...             ...\n",
            "995  DeepIGeoS: A Deep Interactive Geodesic Framewo...               0\n",
            "996  3D Densely Convolutional Networks for Volumetr...               0\n",
            "997  UI-Net: Interactive Artificial Neural Networks...               0\n",
            "998  One-Shot Learning for Semantic Segmentation Lo...               0\n",
            "999  Exploring and Exploiting Diversity for Image S...               0\n",
            "\n",
            "[1000 rows x 2 columns]\n"
          ]
        }
      ]
    }
  ]
}